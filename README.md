# 技术路线

## 1. 图片数据预处理

### 1.1 数据清洗和标注

在深度学习中，数据清洗和标注是非常重要的一步。数据清洗可以帮助我们去除数据中的噪声和异常值，从而提高模型的准确性和鲁棒性。数据标注可以帮助我们为每个数据样本添加标签，从而让模型能够学习到不同类别之间的差异和相似之处。

在本项目中，我们对数据进行了清洗和标注。首先，我们去除了数据中的噪声和异常值，以确保数据的质量。然后，我们为每个数据样本添加了标签，以便模型能够学习到不同类别之间的差异和相似之处。

## 1.2 数据增强

数据增强是一种常用的数据预处理技术，它可以帮助我们增加数据的多样性，从而提高模型的泛化能力。在本项目中，我们采用了多种数据增强技术，包括高斯噪声、亮度变化、左右翻转、上下翻转、色彩抖动、对比度变化和锐度变化等。

这些技术可以帮助我们增加数据的多样性，从而让模型能够学习到更多的特征和模式。例如，左右翻转和上下翻转可以帮助模型学习到不同角度下的图像特征，色彩抖动和对比度变化可以帮助模型学习到不同光照条件下的图像特征，锐度变化可以帮助模型学习到更加清晰的图像特征。

## 2. 模型选择

在本项目中，我们选择了卷积神经网络（CNN）作为模型。CNN是一种专门用于处理图像数据的神经网络，它可以自动提取图像特征，适合处理大规模图像数据。在图像识别方面，CNN表现出色，已经成为了图像识别领域的主流模型。

CNN的优点在于它可以自动提取图像特征，不需要手动设计特征。这样可以大大减少人工干预的成本，同时也可以提高模型的准确性和鲁棒性。此外，CNN还可以通过卷积和池化等操作来减少参数数量，从而提高模型的训练速度和泛化能力。

## 3. 模型训练

在本项目中，我们使用PyTorch框架进行模型训练。首先，我们将数据集分为训练集和验证集，然后，使用预训练的ResNet-50模型作为初始模型，对其进行微调，以适应本项目的数据集。最后，对模型进行训练，训练过程中使用学习率衰减和早停策略，以防止过拟合。

微调是指在预训练模型的基础上，对模型的某些层进行重新训练，以适应新的数据集。在本项目中，我们使用了预训练的ResNet-50模型作为初始模型，然后对其最后一层进行重新训练，以适应本项目的数据集。这样可以大大减少模型的训练时间和计算成本，同时也可以提高模型的准确性和鲁棒性。

学习率衰减和早停策略是常用的防止过拟合的技术。学习率衰减可以帮助我们在训练过程中逐渐降低学习率，从而让模型更加稳定地收敛。早停策略可以帮助我们在模型开始出现过拟合的时候及时停止训练，从而避免模型过度拟合训练数据。

## 4. 模型测试

使用测试集对模型进行测试，评估模型性能。本项目使用准确率作为评估指标，即正确分类的样本数占总样本数的比例。

准确率是评估模型性能的重要指标之一。在本项目中，我们使用准确率作为评估指标，因为它可以直观地反映模型的分类能力。同时，我们还可以使用其他指标来评估模型的性能，例如精确率、召回率和F1值等。这些指标可以帮助我们更加全面地评估模型的性能，从而提高模型的准确性和鲁棒性。


## Q & A

### 图片预处理作用？
预处理可以增强模型的鲁棒性和泛化能力，使其更好地适应不同的场景和数据集。

### 为什么选择ResNet-50模型？
选择ResNet50的原因是因为它是一种更深的卷积神经网络，可以更好地提取图像中的特征，从而提高图像识别和分类的准确率

## 专有名词解释

### 鲁棒性
鲁棒性通常指模型对于噪声、干扰、变形、缺失等异常情况的容忍度和适应能力

### 泛化性
泛化能力是指机器学习模型在处理未曾见过的数据时的表现能力，即模型对新数据的适应能力

### CNN(卷积神经网络)
CNN是一种深度学习模型，主要用于图像识别和分类。它的作用是提取图片特征，然后将特征总合起来得到一个模型。

### 学习率衰减
学习率衰减是指在训练过程中逐渐降低学习率的策略，可以使模型更加稳定地收敛（也就是更符合预期吧）

### 早停策略
早停策略是指在训练过程中，当模型在验证集上的性能不再提升时，就停止训练，以避免过拟合

### 过拟合
过拟合是指机器学习模型在训练数据上表现良好，但在测试数据上表现较差的现象。



